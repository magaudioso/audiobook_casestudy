{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobook ML classifier\n",
    "#### Using the data collected and preprocessed in 'PreProcessedAudiobookData', train our model\n",
    "\n",
    "#### Goal: Create an ML algorithim that will work on a model that will predict the retention of a customer\n",
    "#### Simplier: Classificaiton problem with two classes(outpus) (will they/wont they be retained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "#### All the data was preprocessed, therefore, all we gotta do is split into targets/inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs = npz['inputs'].astype(np.float)\n",
    "validation_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs = npz['inputs'].astype(np.float)\n",
    "test_targets = npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "##### Outline the model(hidden/non-hidden layers, depth, width etc.)\n",
    "##### State loss func\n",
    "##### State optimization algorithim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 1s - loss: 0.5246 - accuracy: 0.7231 - val_loss: 0.4340 - val_accuracy: 0.7852\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.4142 - accuracy: 0.7756 - val_loss: 0.3989 - val_accuracy: 0.7808\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.3825 - accuracy: 0.7944 - val_loss: 0.3791 - val_accuracy: 0.7942\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.3657 - accuracy: 0.8027 - val_loss: 0.3714 - val_accuracy: 0.7942\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.3579 - accuracy: 0.8036 - val_loss: 0.3656 - val_accuracy: 0.7919\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.3539 - accuracy: 0.8013 - val_loss: 0.3679 - val_accuracy: 0.7942\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.3479 - accuracy: 0.8094 - val_loss: 0.3585 - val_accuracy: 0.8054\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.3455 - accuracy: 0.8094 - val_loss: 0.3585 - val_accuracy: 0.8009\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.3355 - accuracy: 0.8201 - val_loss: 0.3705 - val_accuracy: 0.8009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ad49c2910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_size = 10\n",
    "output_size = 2\n",
    "#use same hidden layer size for both width/depth\n",
    "hidden_layer_size = 100\n",
    "\n",
    "#build model \n",
    "model = tf.keras.Sequential([\n",
    "#no need for flattening bc this we already flattened during preprocessing(vectorizedddd)   \n",
    "#tf.keras.layers.Dense() is essentially = output = activation_func(dot(input,weight) + bias)\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "#do the same dot product using .layers.Dense(), except set the number of outputs\n",
    "#use 'softmax' activation func so that we get the properly size output tensor\n",
    "        tf.keras.layers.Dense(output_size, activation = 'softmax')  \n",
    "        ])\n",
    "\n",
    "#choose the optimizer using .compile()\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "#no need to batch out data and iterate through it because while training .fit() method will\n",
    "#batch out for us\n",
    "BATCH_SIZE = 100\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "#early stopping; set an earlytstopping mechanism using .callbacks.EarlyStopping object\n",
    "#patience = 2 bc we want some tolerance for overfitting, but not massive\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 1)\n",
    "\n",
    "#train the model\n",
    "#we do not need to batch the data bc the train/test/validate data are not iterables\n",
    "#.fit() will batch for us\n",
    "model.fit(train_inputs, \n",
    "          train_targets, \n",
    "          batch_size = BATCH_SIZE, \n",
    "          epochs = MAX_EPOCHS,\n",
    "          callbacks = [early_stopping],\n",
    "          validation_data = (validation_inputs, validation_targets), \n",
    "          verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8237\n",
      "Test loss:0.34   Test Accuracy:82.37%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
    "\n",
    "print('Test loss:{0:.2f}   Test Accuracy:{1:.2f}%'.format(test_loss, test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.8_TF2.0]",
   "language": "python",
   "name": "conda-env-python3.8_TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
